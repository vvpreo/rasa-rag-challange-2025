# This file contains the different endpoints your bot can use.

# Server where the models are pulled from.
# https://rasa.com/docs/rasa-pro/production/model-storage#fetching-models-from-a-server

#models:
#  url: http://my-server.com/models/default_core@latest
#  wait_time_between_pulls:  10   # [optional](default: 100)

# Server which runs your custom actions.
# https://rasa.com/docs/rasa-pro/concepts/custom-actions

action_endpoint:
  actions_module: "actions"

# Tracker store which is used to store the conversations.
# By default the conversations are stored in memory.
# https://rasa.com/docs/rasa-pro/production/tracker-stores

#tracker_store:
#    type: redis
#    url: <host of the redis instance, e.g. localhost>
#    port: <port of your redis instance, usually 6379>
#    db: <number of your database within redis, e.g. 0>
#    password: <password used for authentication>
#    use_ssl: <whether or not the communication is encrypted, default false>

#tracker_store:
#    type: mongod
#    url: <url to your mongo instance, e.g. mongodb://localhost:27017>
#    db: <name of the db within your mongo instance, e.g. rasa>
#    username: <username used for authentication>
#    password: <password used for authentication>

# Event broker which all conversation events should be streamed to.
# https://rasa.com/docs/rasa-pro/production/event-brokers

#event_broker:
#  url: localhost
#  username: username
#  password: password
#  queue: queue

vector_store:
  api_key: VECTOR_API_KEY
  collection: COLLECTION_NAME


nlg:
  type: rephrase
  #  rephrase_all: true
  llm:
    model_group: rephraser


model_groups:
  - id: rephraser
    models:
      - provider: rasa
        model: rasa/cmd_gen_codellama_13b_calm_demo
        api_base: "https://tutorial-llm.rasa.ai"
  - id: openrouter_gateway
    models:
      - provider: self-hosted
        # DEFAULT
        # model: openai/chatgpt-4o-latest
        # UNSTABLE
        # model: mistralai/mixtral-8x22b
        # EXPENSIVE and STRANGE...
        # model: anthropic/claude-3-opus
        # BAD
        # model: cohere/command-r-plus
        # DEFINITELY NOT BAD
        model: openai/o1-mini
        api_base: "https://openrouter.ai/api/v1"
        api_key: ${OPENROUTER_API_KEY}
  - id: cmd_generator_finetuned
    models:
      - provider: self-hosted
        model: vvpreo/rasa_2025
        api_base: "https://9leoxw5uuafpsj-8000.proxy.runpod.net/v1"
        api_key: ${RUNPOD_MODEL_KEY}

